{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1, 2, 1], [1, 3, 2], [1, 3, 4], [1, 5, 5], [1, 7, 5], [1, 2, 5], [1, 6, 6], [1, 7, 7]]\n",
    "y_data = [[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0]]\n",
    "\n",
    "# Evaluation our model using this test dataset\n",
    "x_test = [[2, 1, 1], [3, 1, 2], [3, 3, 4]]\n",
    "y_test = [[0, 0, 1], [0, 0, 1], [0, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn.preprocessing as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", shape=[None,3])\n",
    "Y = tf.placeholder(\"float\", shape=[None,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([3,3]),name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]),name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo = tf.nn.softmax(tf.matmul(X,W)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypo), axis = 1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-10).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.argmax(hypo,1)\n",
    "is_correct = tf.equal(prediction, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "200 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "400 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "600 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "800 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "1000 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "1200 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "1400 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "1600 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "1800 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "2000 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "2200 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "2400 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "2600 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "2800 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "3000 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "3200 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "3400 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "3600 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "3800 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "4000 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "4200 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "4400 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "4600 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "4800 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "5000 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "5200 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "5400 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "5600 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "5800 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "6000 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "6200 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "6400 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "6600 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "6800 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "7000 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "7200 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "7400 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "7600 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "7800 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "8000 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "8200 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "8400 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "8600 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "8800 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "9000 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "9200 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "9400 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "9600 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "9800 cost : 7.8676467 W : [[ 0.374398    0.4873415  -0.49431375]\n",
      " [-0.5422413   1.5732374  -1.0102099 ]\n",
      " [ 1.3078514   2.1570709   1.4953691 ]]\n",
      "prediction : [1 1 1]\n",
      "accuracy : 0.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10000):\n",
    "        cost_val,W_val,_ = sess.run([cost,W,optimizer],feed_dict={X : x_data, Y : y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step,\"cost :\",cost_val,\"W :\",W_val)\n",
    "    print(\"prediction :\",sess.run(prediction,feed_dict={X : x_test}))\n",
    "    print(\"accuracy :\",sess.run(accuracy,feed_dict={X:x_test,Y:y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "              [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "              [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "              [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "              [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "              [819, 823, 1198100, 816, 820.450012],\n",
    "              [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "              [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = sk.MinMaxScaler(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True,\n",
       "       feature_range=array([[8.28660e+02, 8.33450e+02, 9.08100e+05, 8.28350e+02, 8.31660e+02],\n",
       "       [8.23020e+02, 8.28070e+02, 1.82810e+06, 8.21655e+02, 8.28070e+02],\n",
       "       [8.19930e+02, 8.24400e+02, 1.43810e+06, 8.18980e+02, 8.24160e+02],\n",
       "       [8.16000e+02, 8.20959e+02, 1.00810e+06, 8.15490e+02, 8.19....09780e+02, 8.13670e+02],\n",
       "       [8.09510e+02, 8.16660e+02, 1.39810e+06, 8.04540e+02, 8.09560e+02]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
