{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt(\"data-03-diabetes.csv\",delimiter=',',dtype= np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,shape=[None,8])\n",
    "Y = tf.placeholder(tf.float32,shape=[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([8,1]),name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]),name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.sigmoid(tf.matmul(W, X) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_18' with dtype float and shape [?,8]\n\t [[node Placeholder_18 (defined at <ipython-input-92-26c33fd3f123>:6)  = Placeholder[dtype=DT_FLOAT, shape=[?,8], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_18', defined at:\n  File \"/Users/charming/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/charming/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-92-26c33fd3f123>\", line 6, in <module>\n    X = tf.placeholder(tf.float32, shape=[None, 8])\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1747, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5206, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_18' with dtype float and shape [?,8]\n\t [[node Placeholder_18 (defined at <ipython-input-92-26c33fd3f123>:6)  = Placeholder[dtype=DT_FLOAT, shape=[?,8], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_18' with dtype float and shape [?,8]\n\t [[{{node Placeholder_18}} = Placeholder[dtype=DT_FLOAT, shape=[?,8], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-2f93080c2c97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_18' with dtype float and shape [?,8]\n\t [[node Placeholder_18 (defined at <ipython-input-92-26c33fd3f123>:6)  = Placeholder[dtype=DT_FLOAT, shape=[?,8], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_18', defined at:\n  File \"/Users/charming/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/charming/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-92-26c33fd3f123>\", line 6, in <module>\n    X = tf.placeholder(tf.float32, shape=[None, 8])\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1747, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5206, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/Users/charming/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_18' with dtype float and shape [?,8]\n\t [[node Placeholder_18 (defined at <ipython-input-92-26c33fd3f123>:6)  = Placeholder[dtype=DT_FLOAT, shape=[?,8], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    feed = {X : x_data, Y: y_data}\n",
    "    for step in range(10001):\n",
    "        sess.run(train,feed_dict=feed)\n",
    "        if step % 200 == 0:\n",
    "            print(step,sess.run(cost,feed_dict=feed))\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict=feed)\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.71942246\n",
      "200 0.69416535\n",
      "400 0.6750173\n",
      "600 0.65833724\n",
      "800 0.643321\n",
      "1000 0.629714\n",
      "1200 0.6173678\n",
      "1400 0.6061601\n",
      "1600 0.5959815\n",
      "1800 0.586732\n",
      "2000 0.57832086\n",
      "2200 0.5706652\n",
      "2400 0.5636904\n",
      "2600 0.5573289\n",
      "2800 0.5515197\n",
      "3000 0.5462081\n",
      "3200 0.5413446\n",
      "3400 0.5368853\n",
      "3600 0.53279054\n",
      "3800 0.529025\n",
      "4000 0.5255569\n",
      "4200 0.52235794\n",
      "4400 0.51940316\n",
      "4600 0.5166697\n",
      "4800 0.51413745\n",
      "5000 0.5117884\n",
      "5200 0.50960636\n",
      "5400 0.5075767\n",
      "5600 0.5056865\n",
      "5800 0.50392395\n",
      "6000 0.5022786\n",
      "6200 0.5007408\n",
      "6400 0.4993021\n",
      "6600 0.49795452\n",
      "6800 0.49669105\n",
      "7000 0.49550536\n",
      "7200 0.49439153\n",
      "7400 0.49334428\n",
      "7600 0.49235877\n",
      "7800 0.49143055\n",
      "8000 0.49055567\n",
      "8200 0.4897302\n",
      "8400 0.48895094\n",
      "8600 0.4882146\n",
      "8800 0.48751852\n",
      "9000 0.48685992\n",
      "9200 0.48623633\n",
      "9400 0.48564544\n",
      "9600 0.48508534\n",
      "9800 0.48455396\n",
      "10000 0.4840496\n",
      "\n",
      "Hypothesis:  [[0.3988263 ]\n",
      " [0.9118726 ]\n",
      " [0.20282917]\n",
      " [0.9395957 ]\n",
      " [0.19543438]\n",
      " [0.74257934]\n",
      " [0.93621397]\n",
      " [0.5793686 ]\n",
      " [0.22809811]\n",
      " [0.5510488 ]\n",
      " [0.7237516 ]\n",
      " [0.17920059]\n",
      " [0.26763535]\n",
      " [0.21359184]\n",
      " [0.7243408 ]\n",
      " [0.514904  ]\n",
      " [0.720878  ]\n",
      " [0.8537998 ]\n",
      " [0.8250656 ]\n",
      " [0.6302722 ]\n",
      " [0.6832642 ]\n",
      " [0.11793368]\n",
      " [0.63315725]\n",
      " [0.66770035]\n",
      " [0.37503415]\n",
      " [0.9254919 ]\n",
      " [0.5338323 ]\n",
      " [0.66069365]\n",
      " [0.6919182 ]\n",
      " [0.44942942]\n",
      " [0.94316673]\n",
      " [0.86327213]\n",
      " [0.5590867 ]\n",
      " [0.8141592 ]\n",
      " [0.3663429 ]\n",
      " [0.64019275]\n",
      " [0.82299614]\n",
      " [0.5957924 ]\n",
      " [0.45088455]\n",
      " [0.39665428]\n",
      " [0.806441  ]\n",
      " [0.1910903 ]\n",
      " [0.37959275]\n",
      " [0.06566006]\n",
      " [0.55648273]\n",
      " [0.92161924]\n",
      " [0.6946502 ]\n",
      " [0.70019233]\n",
      " [0.93012625]\n",
      " [0.92183876]\n",
      " [0.9262717 ]\n",
      " [0.24620835]\n",
      " [0.3556512 ]\n",
      " [0.9501426 ]\n",
      " [0.20750412]\n",
      " [0.58002895]\n",
      " [0.15661624]\n",
      " [0.72707707]\n",
      " [0.8672757 ]\n",
      " [0.49681866]\n",
      " [0.9436039 ]\n",
      " [0.6980034 ]\n",
      " [0.65003383]\n",
      " [0.83074754]\n",
      " [0.59698486]\n",
      " [0.63167924]\n",
      " [0.9497139 ]\n",
      " [0.6973678 ]\n",
      " [0.85680467]\n",
      " [0.6604505 ]\n",
      " [0.29994887]\n",
      " [0.7148639 ]\n",
      " [0.9104857 ]\n",
      " [0.9005951 ]\n",
      " [0.88140213]\n",
      " [0.7818116 ]\n",
      " [0.42112923]\n",
      " [0.83594054]\n",
      " [0.8520798 ]\n",
      " [0.9129996 ]\n",
      " [0.8730087 ]\n",
      " [0.7879939 ]\n",
      " [0.43130708]\n",
      " [0.82225055]\n",
      " [0.5369363 ]\n",
      " [0.8772638 ]\n",
      " [0.42464066]\n",
      " [0.87417704]\n",
      " [0.9293283 ]\n",
      " [0.7651304 ]\n",
      " [0.84283036]\n",
      " [0.6453129 ]\n",
      " [0.7233313 ]\n",
      " [0.570032  ]\n",
      " [0.8857606 ]\n",
      " [0.97059184]\n",
      " [0.8832966 ]\n",
      " [0.668718  ]\n",
      " [0.2722279 ]\n",
      " [0.6170052 ]\n",
      " [0.62129706]\n",
      " [0.9572031 ]\n",
      " [0.7837345 ]\n",
      " [0.756387  ]\n",
      " [0.8963154 ]\n",
      " [0.6690555 ]\n",
      " [0.9235038 ]\n",
      " [0.83426005]\n",
      " [0.4972828 ]\n",
      " [0.3123858 ]\n",
      " [0.93619114]\n",
      " [0.86809146]\n",
      " [0.41137248]\n",
      " [0.46593007]\n",
      " [0.6312519 ]\n",
      " [0.8251957 ]\n",
      " [0.8388608 ]\n",
      " [0.91778105]\n",
      " [0.19183654]\n",
      " [0.7045975 ]\n",
      " [0.8591367 ]\n",
      " [0.6245735 ]\n",
      " [0.6261358 ]\n",
      " [0.82691276]\n",
      " [0.72137845]\n",
      " [0.8394613 ]\n",
      " [0.8263816 ]\n",
      " [0.6296744 ]\n",
      " [0.48004228]\n",
      " [0.4057785 ]\n",
      " [0.426791  ]\n",
      " [0.7691614 ]\n",
      " [0.9268295 ]\n",
      " [0.8180773 ]\n",
      " [0.79587466]\n",
      " [0.8414925 ]\n",
      " [0.4602951 ]\n",
      " [0.789477  ]\n",
      " [0.7256312 ]\n",
      " [0.72608006]\n",
      " [0.87404096]\n",
      " [0.62120783]\n",
      " [0.541822  ]\n",
      " [0.68166053]\n",
      " [0.9033597 ]\n",
      " [0.76416713]\n",
      " [0.46324536]\n",
      " [0.91410816]\n",
      " [0.66470546]\n",
      " [0.76076084]\n",
      " [0.29074362]\n",
      " [0.40260965]\n",
      " [0.12467096]\n",
      " [0.27311957]\n",
      " [0.9013021 ]\n",
      " [0.8628424 ]\n",
      " [0.94006187]\n",
      " [0.12968592]\n",
      " [0.5175749 ]\n",
      " [0.7937256 ]\n",
      " [0.62460774]\n",
      " [0.8468771 ]\n",
      " [0.4367007 ]\n",
      " [0.79932904]\n",
      " [0.573456  ]\n",
      " [0.63764447]\n",
      " [0.71904385]\n",
      " [0.8662121 ]\n",
      " [0.7676518 ]\n",
      " [0.6233215 ]\n",
      " [0.867494  ]\n",
      " [0.89659745]\n",
      " [0.94931793]\n",
      " [0.24182498]\n",
      " [0.8188383 ]\n",
      " [0.35354954]\n",
      " [0.4153507 ]\n",
      " [0.43086106]\n",
      " [0.8731993 ]\n",
      " [0.6607332 ]\n",
      " [0.92400914]\n",
      " [0.89814174]\n",
      " [0.5852624 ]\n",
      " [0.13195285]\n",
      " [0.17655967]\n",
      " [0.6742637 ]\n",
      " [0.74712574]\n",
      " [0.643499  ]\n",
      " [0.81472915]\n",
      " [0.6388231 ]\n",
      " [0.34586236]\n",
      " [0.23102324]\n",
      " [0.8695535 ]\n",
      " [0.41794273]\n",
      " [0.85308766]\n",
      " [0.88657   ]\n",
      " [0.74328244]\n",
      " [0.6049109 ]\n",
      " [0.5960234 ]\n",
      " [0.58912855]\n",
      " [0.6691602 ]\n",
      " [0.93916494]\n",
      " [0.77674234]\n",
      " [0.78279954]\n",
      " [0.1372532 ]\n",
      " [0.35330454]\n",
      " [0.90729105]\n",
      " [0.20512411]\n",
      " [0.918018  ]\n",
      " [0.30253935]\n",
      " [0.25743026]\n",
      " [0.47905526]\n",
      " [0.71486187]\n",
      " [0.22476451]\n",
      " [0.7644211 ]\n",
      " [0.7179254 ]\n",
      " [0.7920603 ]\n",
      " [0.6709971 ]\n",
      " [0.13705955]\n",
      " [0.38273123]\n",
      " [0.68159604]\n",
      " [0.5168655 ]\n",
      " [0.917351  ]\n",
      " [0.9403063 ]\n",
      " [0.6948416 ]\n",
      " [0.34871206]\n",
      " [0.03740255]\n",
      " [0.6865069 ]\n",
      " [0.39379025]\n",
      " [0.47738776]\n",
      " [0.95086664]\n",
      " [0.63581014]\n",
      " [0.94870627]\n",
      " [0.24241892]\n",
      " [0.1451185 ]\n",
      " [0.2589558 ]\n",
      " [0.7375363 ]\n",
      " [0.8991374 ]\n",
      " [0.8856476 ]\n",
      " [0.6172385 ]\n",
      " [0.6439603 ]\n",
      " [0.6092453 ]\n",
      " [0.13817893]\n",
      " [0.53830504]\n",
      " [0.13489172]\n",
      " [0.5531339 ]\n",
      " [0.8509271 ]\n",
      " [0.64670753]\n",
      " [0.7052816 ]\n",
      " [0.946137  ]\n",
      " [0.7925946 ]\n",
      " [0.72991455]\n",
      " [0.7525845 ]\n",
      " [0.7463966 ]\n",
      " [0.8316514 ]\n",
      " [0.3298365 ]\n",
      " [0.39102924]\n",
      " [0.50901586]\n",
      " [0.80283254]\n",
      " [0.6245181 ]\n",
      " [0.67281526]\n",
      " [0.8201705 ]\n",
      " [0.32398692]\n",
      " [0.5040825 ]\n",
      " [0.5893804 ]\n",
      " [0.60382557]\n",
      " [0.45205972]\n",
      " [0.9013157 ]\n",
      " [0.75388247]\n",
      " [0.94197464]\n",
      " [0.5483847 ]\n",
      " [0.8154518 ]\n",
      " [0.77427024]\n",
      " [0.80629164]\n",
      " [0.6726494 ]\n",
      " [0.8363543 ]\n",
      " [0.3523097 ]\n",
      " [0.5905348 ]\n",
      " [0.6772602 ]\n",
      " [0.36498618]\n",
      " [0.8110443 ]\n",
      " [0.29840514]\n",
      " [0.66493   ]\n",
      " [0.9253425 ]\n",
      " [0.80415726]\n",
      " [0.8694766 ]\n",
      " [0.70171565]\n",
      " [0.5460953 ]\n",
      " [0.667462  ]\n",
      " [0.3650016 ]\n",
      " [0.4681519 ]\n",
      " [0.62623847]\n",
      " [0.624478  ]\n",
      " [0.6458359 ]\n",
      " [0.6115582 ]\n",
      " [0.20300288]\n",
      " [0.67632496]\n",
      " [0.9187708 ]\n",
      " [0.55757755]\n",
      " [0.60691184]\n",
      " [0.7867247 ]\n",
      " [0.44347537]\n",
      " [0.6850349 ]\n",
      " [0.49578318]\n",
      " [0.70983243]\n",
      " [0.880165  ]\n",
      " [0.6805908 ]\n",
      " [0.6817898 ]\n",
      " [0.84174794]\n",
      " [0.55633086]\n",
      " [0.8543297 ]\n",
      " [0.93420494]\n",
      " [0.3005474 ]\n",
      " [0.7980027 ]\n",
      " [0.23763864]\n",
      " [0.73884356]\n",
      " [0.7918678 ]\n",
      " [0.646351  ]\n",
      " [0.37849626]\n",
      " [0.7807746 ]\n",
      " [0.7155309 ]\n",
      " [0.7565358 ]\n",
      " [0.1793329 ]\n",
      " [0.8443012 ]\n",
      " [0.851231  ]\n",
      " [0.5322154 ]\n",
      " [0.9376025 ]\n",
      " [0.2703575 ]\n",
      " [0.67529505]\n",
      " [0.94199187]\n",
      " [0.24428917]\n",
      " [0.47397667]\n",
      " [0.68711936]\n",
      " [0.34684756]\n",
      " [0.19231197]\n",
      " [0.8296035 ]\n",
      " [0.9158458 ]\n",
      " [0.8463811 ]\n",
      " [0.6326973 ]\n",
      " [0.678697  ]\n",
      " [0.61449826]\n",
      " [0.74736094]\n",
      " [0.79204243]\n",
      " [0.923929  ]\n",
      " [0.7415992 ]\n",
      " [0.78286016]\n",
      " [0.5899788 ]\n",
      " [0.9324422 ]\n",
      " [0.9352587 ]\n",
      " [0.7613213 ]\n",
      " [0.27737197]\n",
      " [0.69946295]\n",
      " [0.33393008]\n",
      " [0.777797  ]\n",
      " [0.22250992]\n",
      " [0.23630957]\n",
      " [0.41927078]\n",
      " [0.72500587]\n",
      " [0.40604553]\n",
      " [0.55627334]\n",
      " [0.84129953]\n",
      " [0.6366945 ]\n",
      " [0.8087265 ]\n",
      " [0.94589317]\n",
      " [0.77846414]\n",
      " [0.11149469]\n",
      " [0.4936344 ]\n",
      " [0.8439718 ]\n",
      " [0.8651587 ]\n",
      " [0.6955381 ]\n",
      " [0.30393133]\n",
      " [0.8699183 ]\n",
      " [0.904989  ]\n",
      " [0.32791278]\n",
      " [0.6896242 ]\n",
      " [0.8503986 ]\n",
      " [0.8015522 ]\n",
      " [0.8504639 ]\n",
      " [0.90101045]\n",
      " [0.8637637 ]\n",
      " [0.90397036]\n",
      " [0.6641209 ]\n",
      " [0.6391221 ]\n",
      " [0.5529705 ]\n",
      " [0.8413127 ]\n",
      " [0.8767928 ]\n",
      " [0.25521177]\n",
      " [0.7678432 ]\n",
      " [0.8593435 ]\n",
      " [0.34188908]\n",
      " [0.6059087 ]\n",
      " [0.86351305]\n",
      " [0.52485436]\n",
      " [0.9033544 ]\n",
      " [0.25344032]\n",
      " [0.82621604]\n",
      " [0.6570835 ]\n",
      " [0.8610939 ]\n",
      " [0.35030526]\n",
      " [0.7071702 ]\n",
      " [0.71702737]\n",
      " [0.76189184]\n",
      " [0.09992125]\n",
      " [0.2325268 ]\n",
      " [0.6918411 ]\n",
      " [0.82504743]\n",
      " [0.48697048]\n",
      " [0.7840708 ]\n",
      " [0.49604008]\n",
      " [0.34913874]\n",
      " [0.82673526]\n",
      " [0.4620058 ]\n",
      " [0.91168123]\n",
      " [0.80479205]\n",
      " [0.72228813]\n",
      " [0.9146728 ]\n",
      " [0.70397484]\n",
      " [0.7732251 ]\n",
      " [0.36002907]\n",
      " [0.29315135]\n",
      " [0.7387211 ]\n",
      " [0.43102366]\n",
      " [0.51677716]\n",
      " [0.90112704]\n",
      " [0.88153964]\n",
      " [0.90996414]\n",
      " [0.9475921 ]\n",
      " [0.6761868 ]\n",
      " [0.8683134 ]\n",
      " [0.36926118]\n",
      " [0.35427824]\n",
      " [0.47539794]\n",
      " [0.92229104]\n",
      " [0.6251364 ]\n",
      " [0.17047976]\n",
      " [0.92947626]\n",
      " [0.8093265 ]\n",
      " [0.57853836]\n",
      " [0.759772  ]\n",
      " [0.03956725]\n",
      " [0.9139122 ]\n",
      " [0.7951619 ]\n",
      " [0.7630197 ]\n",
      " [0.752964  ]\n",
      " [0.9578615 ]\n",
      " [0.62899774]\n",
      " [0.7787062 ]\n",
      " [0.7204293 ]\n",
      " [0.85787475]\n",
      " [0.16446383]\n",
      " [0.61803365]\n",
      " [0.90749186]\n",
      " [0.61861944]\n",
      " [0.73285943]\n",
      " [0.9365617 ]\n",
      " [0.86328965]\n",
      " [0.86736536]\n",
      " [0.5265065 ]\n",
      " [0.74765694]\n",
      " [0.93009925]\n",
      " [0.7606589 ]\n",
      " [0.6215606 ]\n",
      " [0.36420143]\n",
      " [0.49418283]\n",
      " [0.50051296]\n",
      " [0.58599406]\n",
      " [0.532475  ]\n",
      " [0.7618828 ]\n",
      " [0.5422557 ]\n",
      " [0.80436784]\n",
      " [0.81156623]\n",
      " [0.7374591 ]\n",
      " [0.6385429 ]\n",
      " [0.48179278]\n",
      " [0.5793332 ]\n",
      " [0.9298514 ]\n",
      " [0.85118693]\n",
      " [0.2701828 ]\n",
      " [0.4580781 ]\n",
      " [0.5095507 ]\n",
      " [0.12957905]\n",
      " [0.86045885]\n",
      " [0.14889176]\n",
      " [0.9071532 ]\n",
      " [0.8736682 ]\n",
      " [0.8201764 ]\n",
      " [0.68449914]\n",
      " [0.8844933 ]\n",
      " [0.3511007 ]\n",
      " [0.75936586]\n",
      " [0.9365832 ]\n",
      " [0.2954268 ]\n",
      " [0.44289273]\n",
      " [0.87383336]\n",
      " [0.866753  ]\n",
      " [0.66361547]\n",
      " [0.8155837 ]\n",
      " [0.8146307 ]\n",
      " [0.8049638 ]\n",
      " [0.29302004]\n",
      " [0.75420594]\n",
      " [0.89911944]\n",
      " [0.61444324]\n",
      " [0.76412517]\n",
      " [0.6580005 ]\n",
      " [0.7941425 ]\n",
      " [0.8571442 ]\n",
      " [0.9198848 ]\n",
      " [0.5902071 ]\n",
      " [0.43672812]\n",
      " [0.75800514]\n",
      " [0.717978  ]\n",
      " [0.9659494 ]\n",
      " [0.77694595]\n",
      " [0.68314606]\n",
      " [0.41622332]\n",
      " [0.69962865]\n",
      " [0.9013573 ]\n",
      " [0.942298  ]\n",
      " [0.88011974]\n",
      " [0.68713856]\n",
      " [0.6386974 ]\n",
      " [0.7978364 ]\n",
      " [0.50618166]\n",
      " [0.8543226 ]\n",
      " [0.78820735]\n",
      " [0.90318424]\n",
      " [0.60161954]\n",
      " [0.7062892 ]\n",
      " [0.8859605 ]\n",
      " [0.5141636 ]\n",
      " [0.59993905]\n",
      " [0.6868699 ]\n",
      " [0.7250623 ]\n",
      " [0.6609092 ]\n",
      " [0.9129877 ]\n",
      " [0.9274069 ]\n",
      " [0.22086583]\n",
      " [0.16088487]\n",
      " [0.74686027]\n",
      " [0.5683608 ]\n",
      " [0.24070354]\n",
      " [0.81920815]\n",
      " [0.90608203]\n",
      " [0.70148104]\n",
      " [0.93440396]\n",
      " [0.91803336]\n",
      " [0.7412421 ]\n",
      " [0.8380579 ]\n",
      " [0.6862001 ]\n",
      " [0.56592983]\n",
      " [0.75323087]\n",
      " [0.6113557 ]\n",
      " [0.12340595]\n",
      " [0.91177964]\n",
      " [0.8704335 ]\n",
      " [0.71911937]\n",
      " [0.90694016]\n",
      " [0.88263965]\n",
      " [0.8800941 ]\n",
      " [0.58757883]\n",
      " [0.6841707 ]\n",
      " [0.88432485]\n",
      " [0.7289533 ]\n",
      " [0.854192  ]\n",
      " [0.902489  ]\n",
      " [0.59505045]\n",
      " [0.8156102 ]\n",
      " [0.80314904]\n",
      " [0.5936571 ]\n",
      " [0.49956325]\n",
      " [0.13054988]\n",
      " [0.286508  ]\n",
      " [0.7919824 ]\n",
      " [0.58510506]\n",
      " [0.68514836]\n",
      " [0.5067327 ]\n",
      " [0.9125279 ]\n",
      " [0.43256935]\n",
      " [0.7909012 ]\n",
      " [0.3060559 ]\n",
      " [0.87749004]\n",
      " [0.37597105]\n",
      " [0.8073842 ]\n",
      " [0.5911565 ]\n",
      " [0.8610442 ]\n",
      " [0.6069216 ]\n",
      " [0.22715859]\n",
      " [0.8071288 ]\n",
      " [0.9296235 ]\n",
      " [0.39114666]\n",
      " [0.9015009 ]\n",
      " [0.85188675]\n",
      " [0.8296869 ]\n",
      " [0.79061925]\n",
      " [0.44491428]\n",
      " [0.30166075]\n",
      " [0.6840583 ]\n",
      " [0.21631423]\n",
      " [0.94424105]\n",
      " [0.3641505 ]\n",
      " [0.9079424 ]\n",
      " [0.8666098 ]\n",
      " [0.40680757]\n",
      " [0.2300845 ]\n",
      " [0.68336403]\n",
      " [0.446527  ]\n",
      " [0.8221873 ]\n",
      " [0.7068523 ]\n",
      " [0.9750069 ]\n",
      " [0.5318263 ]\n",
      " [0.61164826]\n",
      " [0.80987334]\n",
      " [0.7855191 ]\n",
      " [0.09431075]\n",
      " [0.7677345 ]\n",
      " [0.8009635 ]\n",
      " [0.87179226]\n",
      " [0.60831827]\n",
      " [0.47009394]\n",
      " [0.6101155 ]\n",
      " [0.88044834]\n",
      " [0.61989045]\n",
      " [0.7905689 ]\n",
      " [0.79972035]\n",
      " [0.8457739 ]\n",
      " [0.77564365]\n",
      " [0.557879  ]\n",
      " [0.78406304]\n",
      " [0.9011188 ]\n",
      " [0.7367544 ]\n",
      " [0.9489423 ]\n",
      " [0.79278237]\n",
      " [0.6186755 ]\n",
      " [0.48670527]\n",
      " [0.8211616 ]\n",
      " [0.84764004]\n",
      " [0.4739315 ]\n",
      " [0.63208055]\n",
      " [0.23843037]\n",
      " [0.56580293]\n",
      " [0.76374525]\n",
      " [0.9404728 ]\n",
      " [0.8326039 ]\n",
      " [0.7471344 ]\n",
      " [0.7360089 ]\n",
      " [0.8867784 ]\n",
      " [0.4557218 ]\n",
      " [0.92314935]\n",
      " [0.63761437]\n",
      " [0.8680051 ]\n",
      " [0.3060694 ]\n",
      " [0.10353396]\n",
      " [0.32200357]\n",
      " [0.39376575]\n",
      " [0.67873925]\n",
      " [0.84562767]\n",
      " [0.5656946 ]\n",
      " [0.69662315]\n",
      " [0.8084498 ]\n",
      " [0.50139225]\n",
      " [0.38168627]\n",
      " [0.8749129 ]\n",
      " [0.9027658 ]\n",
      " [0.49537483]\n",
      " [0.6933458 ]\n",
      " [0.18036774]\n",
      " [0.3805053 ]\n",
      " [0.73221725]\n",
      " [0.69556147]\n",
      " [0.88092357]\n",
      " [0.97499555]\n",
      " [0.20721503]\n",
      " [0.74955654]\n",
      " [0.6172371 ]\n",
      " [0.46965396]\n",
      " [0.72406024]\n",
      " [0.7061798 ]\n",
      " [0.8636557 ]\n",
      " [0.71604604]\n",
      " [0.56188077]\n",
      " [0.64696056]\n",
      " [0.18596628]\n",
      " [0.71206915]\n",
      " [0.57361096]\n",
      " [0.89636284]\n",
      " [0.5325134 ]\n",
      " [0.55326813]\n",
      " [0.76508445]\n",
      " [0.7234224 ]\n",
      " [0.5078725 ]\n",
      " [0.7587032 ]\n",
      " [0.6235661 ]\n",
      " [0.34190273]\n",
      " [0.6170734 ]\n",
      " [0.8757911 ]\n",
      " [0.8377814 ]\n",
      " [0.57178575]\n",
      " [0.75179154]\n",
      " [0.28843626]\n",
      " [0.85520697]\n",
      " [0.54085606]\n",
      " [0.7648923 ]\n",
      " [0.40552902]\n",
      " [0.60491574]\n",
      " [0.8283684 ]\n",
      " [0.15789366]\n",
      " [0.3273064 ]\n",
      " [0.76527125]\n",
      " [0.8282471 ]\n",
      " [0.7824699 ]\n",
      " [0.8926193 ]\n",
      " [0.8025828 ]\n",
      " [0.6968697 ]\n",
      " [0.7544903 ]\n",
      " [0.7869771 ]\n",
      " [0.7034414 ]\n",
      " [0.8041878 ]\n",
      " [0.4602177 ]\n",
      " [0.43319353]\n",
      " [0.87251973]\n",
      " [0.79363286]\n",
      " [0.6337003 ]\n",
      " [0.34266952]\n",
      " [0.8690108 ]\n",
      " [0.8102841 ]\n",
      " [0.8179125 ]\n",
      " [0.66972655]\n",
      " [0.8692825 ]\n",
      " [0.86460036]\n",
      " [0.7885739 ]\n",
      " [0.46429038]\n",
      " [0.88032806]\n",
      " [0.8998997 ]\n",
      " [0.35279456]\n",
      " [0.19246405]\n",
      " [0.7327593 ]\n",
      " [0.45195794]\n",
      " [0.8484943 ]\n",
      " [0.32554743]\n",
      " [0.42033046]\n",
      " [0.4438169 ]\n",
      " [0.8017935 ]\n",
      " [0.8383275 ]\n",
      " [0.14870721]\n",
      " [0.35958844]\n",
      " [0.6659675 ]\n",
      " [0.49989524]\n",
      " [0.52284634]\n",
      " [0.79675275]\n",
      " [0.17648496]\n",
      " [0.91656846]\n",
      " [0.18840054]\n",
      " [0.824162  ]\n",
      " [0.7396703 ]\n",
      " [0.7125596 ]\n",
      " [0.8151311 ]\n",
      " [0.70802444]\n",
      " [0.88278633]] \n",
      "Correct (Y):  [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  0.77470356\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt('data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 8])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([8, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X, W)))\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "   sess.run(tf.global_variables_initializer())\n",
    "\n",
    "   feed = {X: x_data, Y: y_data}\n",
    "   for step in range(10001):\n",
    "       sess.run(train, feed_dict=feed)\n",
    "       if step % 200 == 0:\n",
    "           print(step, sess.run(cost, feed_dict=feed))\n",
    "\n",
    "   # Accuracy report\n",
    "   h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict=feed)\n",
    "   print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
